---
title: "2: Physical Properties of Lakes"
author: "Water Data Analytics | Kateri Salk"
date: "Spring 2022"
output: pdf_document
geometry: margin=2.54cm
editor_options: 
  chunk_output_type: console
---

## Lesson Objectives
1. Investigate the concepts of lake stratification and mixing by analyzing monitoring data
2. Apply data analytics skills to applied questions about physical properties of lakes
3. Communicate findings with peers through oral, visual, and written modes

## Opening Discussion

What are the physical properties of lakes?
Light transmission, temperature, dissolved oxygen

## Session Set Up
```{r, message = FALSE}
# Check working directory (should be project file location)
getwd()

#you cannot knit a markdown file if there is an active install line of code
# install.packages("tidyverse")
# install.packages("lubridate") helps work with date and time
# install.packages("rLakeAnalyzer")

# load packages
library(tidyverse)
library(lubridate)
library(rLakeAnalyzer)

# Load data; North Temperate Lakes Research Data from Wisconsin
#read_csv is slightly different than read.csv, basically just faster, so use if bigger files.
#relative file paths just start from where your working directory ends
#here package also works with relative pathways
NTLdata <- read.csv("./Data/Raw/NTL-LTER_Lake_ChemistryPhysics_Raw.csv")

# set ggplot theme
theme_set(theme_classic())
```

## Data Wrangling and Exploration

### Investigate structure of dataset

Common steps/checks for data wrangling: 

* Date formatting
* Addressing NAs
* Subsetting and filtering 

```{r}
# Is the date column perceived as a date by R?
#R needs to be explicitly told to recognize data as a date

#class tells us what R is recognizing data as
class(NTLdata$sampledate)
#telling R we want it recognized as date. Make sure you use the same way that the date is written in the data i.e. date, month, two-digit year
#two digit year is lowercase y and four digit is uppercase Y
NTLdata$sampledate <- as.Date(NTLdata$sampledate, format = "%m/%d/%y")
class(NTLdata$sampledate)
# What does this column look like now?
#Now our column has been readjusted to internationally recognized format of year-month-day. It does this change itself and you do the same format as original data

# Remove rows that contain NAs in temperature column
#checks the dimension of the object; we're doing this to later see how many rows we dropped. row is first number then columns
#Pipes %>% for nesting functions
dim(NTLdata)
NTLdata <- NTLdata %>%
  drop_na(temperature_C)
dim(NTLdata)  

# How many observations are there for each lake? Time in lecture 7:45pm
summary(NTLdata$lakename)
#shows how many rows each lake name appears in the data and since we removed the NA it also shows the number of temperature measurements we have
#Peter and Paul have the most measurements and are the most famous of the lakes. One is fertilized and one is a control
summary(as.factor(NTLdata$lakename))

# Let's choose the two lakes with the most data
#filter takes the rows we specify and includes it in new object
#c indicates you are concatenating a list
#the %in% is not a pipe; it represents "include" and satisfies the filter function
#a normal pipe %>% is always outside of parentheses
NTLdata_PeterPaul <- NTLdata %>%
  filter(lakename %in% c("Paul Lake", "Peter Lake"))

# What is another way to use the filter command to get to the same result?
#The vertical line represents the word OR
NTLdata_PeterPaul <- NTLdata %>%
  filter(lakename == "Paul Lake" | lakename == "Peter Lake")

# Make two data frames, one for each lake
Pauldata <- NTLdata %>%
  filter(lakename == "Paul Lake")
Peterdata <- NTLdata %>%
  filter(lakename == "Peter Lake")

# How long did the monitoring last?
#looking for mins and maxs; 1984-2016
min(Pauldata$sampledate)
max(Pauldata$sampledate)
min(Peterdata$sampledate)
max(Peterdata$sampledate)

# Which depths are sampled in each lake?
#brings up a list of the unique values; integers listed first then the 0.5s after
unique(Pauldata$depth)
unique(Peterdata$depth)
# Why didn't we use the "summary" function here?
#it doesn't give us the actual depths and increments just a range

# QA the one data point at 20 m depth. We just do this b/c messes up visualization. Usually have to be very careful removing data!!!
Pauldata <- Pauldata %>%
  filter(depth < 20)

```

### Exploratory data visualization

Let's make a plot of temperatures by depth. There are a lot of points, so adding a 50 % transparency to the points helps us see where points are densely clustered together.

Let's also try using the traditional limnological graph type, with depth on the y axis in reverse, to simulate a cross section of a lake. When and where do we usually observe high and low temperatures?
ggplot uses the + instead of %>% 
alpha stands for transparency so this graph is at 50% transparency
geom_point is the function for a scatterplot
```{r}
ggplot(Pauldata, aes(x = depth, y = temperature_C)) + 
  geom_point(alpha = 0.5) +
  labs(y = expression("Temperature "(degree*C)), x = "Depth (m)")
#temp more variable at surface, temp decreases with depth, seems to get
#IV on x and DV on y classically but flip it to do sort of cross section of lake it's a tradition in limonology to do this. B/c it looks like a lake! Very cool

#The one set of points is the one time of year (nov) when they sampled the lake
#DOY is date of year in the legend
#Thermally mixed is when the lake is same temp at all depths, homogeneous, little resistance to mixing b/c temp all the same; even a little wind can drive the mixing of a homogenous-temp lake. mixing here is moving the water around
#stratified: in summer when temp differs across depths
#epilimnion: top of lake
#hypolimnion: bottom of lake; lots of ressitnace to mixing b/c of the differences in the denisity of water when temps are different. less dense in warmer water.
#Dimictic: Di-two mictic mixing So a dimictic lake mixes twice a year
#Water is densest at 4 degrees celsius and stabalizes there
ggplot(Pauldata, aes(x = temperature_C, y = depth, color = daynum)) +
  geom_point(alpha = 0.5) +
  scale_y_reverse() +
  scale_color_viridis_c() +
  labs(x = expression("Temperature "(degree*C)), y = "Depth (m)", color = "DOY")

```

How do temperatures at the surface compare to temperatures at the mid-depths and at the bottom?
<add notes here>


### Graphing seasonal water profiles

Lakes in the North Temperate Lakes LTER are dimictic, meaning they mix fully twice per year. When the lakes are not mixed (stratified), the top layer (epilimnion) and the bottom layer (hypolimnion) of the lake are different temperatures.

For background information on lake stratification, see this [stratification summary article from the North American Lake Management Society](https://www.nalms.org/secchidipin/monitoring-methods/temperature-and-oxygen/).


In 1993, Paul Lake was sampled from May 20 through November 2. Let's look at temperature profiles of the lake across the year and also explore how this impacts dissolved oxygen.

```{r}
ggplot(subset(Pauldata, year4 == 1993), 
       aes(x = temperature_C, y = depth, color = daynum)) +
  geom_point(alpha = 0.5) +
  scale_y_reverse() +
  scale_color_viridis_c() +
  labs(x = expression("Temperature "(degree*C)), y = "Depth (m)", color = "DOY") 

# Now, make a plot as above but with dissolved oxygen saturation instead of temperature.


```

Why does mixing occur in the spring and fall? What are the mechanisms that make this possible?
<add notes here>



### Calculating thermoclines

[rLakeAnalyzer documentation](https://cran.r-project.org/web/packages/rLakeAnalyzer/rLakeAnalyzer.pdf)

```{r}
Pauldata_thermo <- Pauldata %>%
  group_by(year4, daynum, sampledate) %>%
  # calculate thermoclines based on temperature profiles. 
  # seasonal = FALSE calculates the thermocline as the maximum density gradient
  # seasonal = TRUE calculates the thermocline as the deepest density gradient
  summarise(thermocline = thermo.depth(wtr = temperature_C, depths = depth, seasonal = FALSE)) %>%
  # remove all thermoclines within 1 m of the surface. these can represent transient stratification.
  filter(thermocline > 1)

ggplot(Pauldata_thermo, aes(x = daynum, y = thermocline)) +
  geom_point() 
  
```

How does thermocline depth change over the course of the year? When do we observe the most variability in thermocline depth?
<add notes here>


### Climate change

Increases in global temperature are predicted to cause several changes to lake thermal conditions, including: 

* Increases in surface temperature
* Increases in surface minimum temperature
* Increases in extent of stratification
* Increases in length of stratification
* Decreases in ice cover

Several studies have addressed this topic, using long-term and spatially diverse datasets: 

https://link.springer.com/article/10.1007/s10584-015-1326-1?sa_campaign=email/event/articleAuthor/onlineFirst&error=cookies_not_supported&error=cookies_not_supported&code=2b415e25-de4c-452f-bd02-2cceae08b7a3&code=e63aabb9-76d3-4e49-b36c-e591007a9e9c

http://hpkx.cnjournals.com/uploadfile/news_images/hpkx/2020-07-15/10.1038-s43017-020-0067-5.pdf

https://agupubs.onlinelibrary.wiley.com/doi/pdf/10.1002/2015GL064097

https://link.springer.com/article/10.1007/s10584-019-02465-y

Let's explore how these changes might manifest in Paul Lake. 
```{r}
ggplot(Pauldata_thermo, aes(x = daynum, y = thermocline, color = year4)) +
  geom_point() +
  scale_color_viridis_c()
# exercise: put the legend on top and relabel the aesthetics

ggplot(subset(Pauldata, depth == 1),
       aes(x = daynum, y = temperature_C, color = as.factor(year4))) +
  geom_point(alpha = 0.5) +
  geom_line() +
  scale_color_viridis_d()
# exercise: relabel the aesthetics

```

## Closing Discussion

What are the main concepts you learned about the physical properties of lakes today? What was the evidence for these concepts in the dataset?
